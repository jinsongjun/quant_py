{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 백테스팅 시뮬레이션\n",
    "\n",
    "백테스트란 현재 생각하는 전략을 과거부터 실행했을 때 어떠한 성과가 발생하는지 테스트해보는 과정이다. 과거의 데이터를 기반으로 전략을 실행하는 퀀트 투자에 있어서 이는 핵심 단계다. 백테스트 결과를 통해 해당 전략의 손익뿐만 아니라 각종 위험을 대략적으로 판단할 수 있으며, 어떤 구간에서 전략이 좋았는지 혹은 나빴는지에 대한 이해도 키울 수 있다. 이러한 이해를 바탕으로 퀀트 투자를 지속한다면 단기적으로 수익이 나쁜 구간에서도 그 이유에 대한 객관적인 안목을 키울 수 있으며, 확신을 가지고 전략을 지속할 수 있다.\n",
    "\n",
    "그러나 백테스트를 아무리 보수적으로 혹은 엄밀하게 진행하더라도 이미 일어난 결과를 대상으로 한다는 사실은 변하지 않는다. 백테스트 수익률만을 보고 투자에 대해 판단하거나, 혹은 동일한 수익률이 미래에도 반복될 것이라고 믿는다면 이는 백미러만 보고 운전하는 것처럼 매우 위험한 결과를 초래할 수도 있다.\n",
    "\n",
    "파이썬에는 백테스트를 위한 수많은 패키지들이 존재하며 대표적인 패키지는 다음과 같다.\n",
    "\n",
    "- backtesting: 각종 트레이딩 전략에 최적화된 인터페이스를 제공하며, 앞서 살펴본 TA-Lib 패키지와의 상당한 호환성 및 파라미터에 대한 최적화 기능도 제공한다. \n",
    "```\n",
    "https://kernc.github.io/backtesting.py/\n",
    "```\n",
    "\n",
    "- Backtrader: 구글에서 파이썬 관련 백테스트를 검색하면 가장 많이 검색되는 패키지일 만큼 사용법에 대한 메뉴얼이 잘 구성되어 있다. \n",
    "```\n",
    "https://www.backtrader.com/\n",
    "```\n",
    "\n",
    "- bt: 앞의 패키지들과는 다르게 트레이딩 전략 뿐만 아니라 포트폴리오 기반의 퀀트를 백테스트를 하는데도 매우 유용한 기능들을 제공한다.\n",
    "```\n",
    "https://pmorissette.github.io/bt/\n",
    "```\n",
    "\n",
    "모든 패키지에는 장단점이 있기 마련이기에, 모두 사용해보고 본인에게 맞는것을 선택하는 것이 최고의 방법이다. 본 책에서는 포트폴리오 전략과 트레이딩 전략을 동시에 다루기에 bt 패키지를 사용해 백테스트를 하도록 하겠다. 해당 패키지에는 본 책에서 다루는 내용 외에도 백테스트 및 결과 평가에 대한 수많은 함수들이 존재하기에, 공식 페이지와 github의 코드를 모두 살펴보는 것도 재밌는 작업이다.\n",
    "\n",
    "또한 bt 패키지의 함수는 대부분 ffn 패키지를 기초로 만들어져 있으므로 이 역시 찾아보는 것을 추천한다.\n",
    "\n",
    "```\n",
    "http://pmorissette.github.io/ffn/\n",
    "```\n",
    "\n",
    "## bt 패키지 \n",
    "\n",
    "bt 패키지에서는 백테스트의 과정을 다음과 같이 정의한다.\n",
    "\n",
    "1. 데이터의 수집\n",
    "2. 전략의 정의\n",
    "3. 데이터를 이용한 전략의 백테스트\n",
    "4. 결과에 대한 평가\n",
    "\n",
    "### 데이터의 수집\n",
    "\n",
    "백테스트를 위해서는 먼저 데이터를 준비해야 한다. bt 패키지의 `get()` 함수는 야후 파이낸스 API를 이용해 수정주가를 다운로드 받을 수 있게 해준다. 물론 기존의 Pandas-datareader 패키지나 크롤링을 통해 데이터를 수집할 수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting btNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for bt from https://files.pythonhosted.org/packages/5e/41/ba310c4c92adb702ccb52ec7046adaa188ba3bf17c277460f4514ac92d16/bt-1.0.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading bt-1.0.0-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting ffn>=1.0.0 (from bt)\n",
      "  Downloading ffn-1.0.0.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyprind>=2.11 (from bt)\n",
      "  Using cached PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from ffn>=1.0.0->bt) (5.1.1)\n",
      "Requirement already satisfied: matplotlib>=1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffn>=1.0.0->bt) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffn>=1.0.0->bt) (1.26.2)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffn>=1.0.0->bt) (2.1.3)\n",
      "Requirement already satisfied: pandas-datareader>=0.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffn>=1.0.0->bt) (0.10.0)\n",
      "Collecting scikit-learn>=0.15 (from ffn>=1.0.0->bt)\n",
      "  Obtaining dependency information for scikit-learn>=0.15 from https://files.pythonhosted.org/packages/4e/ba/ce9bd1cd4953336a0e213b29cb80bb11816f2a93de8c99f88ef0b446ad0c/scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=0.15 (from ffn>=1.0.0->bt)\n",
      "  Obtaining dependency information for scipy>=0.15 from https://files.pythonhosted.org/packages/43/d0/f3cd75b62e1b90f48dbf091261b2fc7ceec14a700e308c50f6a69c83d337/scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.4 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.4 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 533.6 kB/s eta 0:00:00\n",
      "Collecting tabulate>=0.7.5 (from ffn>=1.0.0->bt)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: yfinance>=0.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffn>=1.0.0->bt) (0.2.32)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=1->ffn>=1.0.0->bt) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.19->ffn>=1.0.0->bt) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.19->ffn>=1.0.0->bt) (2023.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-datareader>=0.2->ffn>=1.0.0->bt) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-datareader>=0.2->ffn>=1.0.0->bt) (2.31.0)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.15->ffn>=1.0.0->bt)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.15->ffn>=1.0.0->bt)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (0.0.11)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (1.4.4)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (2.3.10)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (3.17.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance>=0.2->ffn>=1.0.0->bt) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2->ffn>=1.0.0->bt) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from html5lib>=1.1->yfinance>=0.2->ffn>=1.0.0->bt) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib>=1.1->yfinance>=0.2->ffn>=1.0.0->bt) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=1.0.0->bt) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=1.0.0->bt) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=1.0.0->bt) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=1.0.0->bt) (2023.11.17)\n",
      "Downloading bt-1.0.0-cp311-cp311-win_amd64.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 216.3/216.3 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/9.2 MB 76.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.2 MB 66.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.2 MB 44.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.2 MB 47.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 48.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 48.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 34.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.7/44.1 MB 57.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 5.6/44.1 MB 59.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 8.2/44.1 MB 65.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 10.9/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 13.9/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 15.1/44.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 18.2/44.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 21.0/44.1 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.9/44.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 26.7/44.1 MB 65.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.4/44.1 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.5/44.1 MB 65.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.5/44.1 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.8/44.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.7/44.1 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.5/44.1 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.1 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.1 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.1 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.1 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.3/44.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.1 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.2/302.2 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: ffn\n",
      "  Building wheel for ffn (pyproject.toml): started\n",
      "  Building wheel for ffn (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ffn: filename=ffn-1.0.0-py3-none-any.whl size=25964 sha256=0c0dadcf24de940cbb70a29712a3c1b41d69413c98639f591c053bf09303f91b\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\e2\\2c\\88\\809333b8a39aca6ae83db3ab1c069cc6cf30bf10588db3b8f0\n",
      "Successfully built ffn\n",
      "Installing collected packages: pyprind, threadpoolctl, tabulate, scipy, joblib, scikit-learn, ffn, bt\n",
      "Successfully installed bt-1.0.0 ffn-1.0.0 joblib-1.3.2 pyprind-2.11.3 scikit-learn-1.3.2 scipy-1.11.4 tabulate-0.9.0 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tabulate.exe is installed in 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spy</th>\n",
       "      <th>tlt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>61.366554</td>\n",
       "      <td>43.262573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>61.555233</td>\n",
       "      <td>43.362839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>62.640095</td>\n",
       "      <td>43.247528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>62.485130</td>\n",
       "      <td>43.402962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>61.582172</td>\n",
       "      <td>43.618587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  spy        tlt\n",
       "Date                            \n",
       "2003-01-02  61.366554  43.262573\n",
       "2003-01-03  61.555233  43.362839\n",
       "2003-01-06  62.640095  43.247528\n",
       "2003-01-07  62.485130  43.402962\n",
       "2003-01-08  61.582172  43.618587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bt\n",
    "\n",
    "data = bt.get(\"SPY, TLT\", start='2003-01-01', end='2021-12-31')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get()` 함수 내에 다운로드 받고자 하는 종목의 티커를 입력하면 수정주가만 데이터프레임 형태로 가공된다. 우리는 이미 받은 글로벌 자산을 대표하는 ETF 데이터를 DB에 저장했기에 이를 불러와 사용하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Obtaining dependency information for sqlalchemy from https://files.pythonhosted.org/packages/67/e7/7c77fd5290646f929b499992607cf1bc940573098a593080fcc8f7e13a08/SQLAlchemy-2.0.23-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.23-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from sqlalchemy)\n",
      "  Obtaining dependency information for typing-extensions>=4.2.0 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/07/e2/91bf652b49f4a7cce91c63e4fe0da518153a52e5f33660f76f971c50ad0e/greenlet-3.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading greenlet-3.0.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Downloading SQLAlchemy-2.0.23-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 279.3 kB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.1/2.1 MB 326.1 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.1 MB 353.1 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.4/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.1-cp311-cp311-win_amd64.whl (288 kB)\n",
      "   ---------------------------------------- 0.0/288.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 288.4/288.4 kB ? eta 0:00:00\n",
      "Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.1 sqlalchemy-2.0.23 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Documents\\office_github\\quant_py\\backtest.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m create_engine\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39m'\u001b[39;49m\u001b[39mmysql+pymysql://root:1234@127.0.0.1:3306/stock_db\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m price \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql(\u001b[39m'\u001b[39m\u001b[39mselect * from sample_etf;\u001b[39m\u001b[39m'\u001b[39m, con\u001b[39m=\u001b[39mengine)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m price \u001b[39m=\u001b[39m price\u001b[39m.\u001b[39mset_index([\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    275\u001b[0m         _warn_with_version(\n\u001b[0;32m    276\u001b[0m             messages[m],\n\u001b[0;32m    277\u001b[0m             versions[m],\n\u001b[0;32m    278\u001b[0m             version_warnings[m],\n\u001b[0;32m    279\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m    280\u001b[0m         )\n\u001b[1;32m--> 281\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:601\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    600\u001b[0m             dbapi_args[k] \u001b[39m=\u001b[39m pop_kwarg(k)\n\u001b[1;32m--> 601\u001b[0m     dbapi \u001b[39m=\u001b[39m dbapi_meth(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdbapi_args)\n\u001b[0;32m    603\u001b[0m dialect_args[\u001b[39m\"\u001b[39m\u001b[39mdbapi\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dbapi\n\u001b[0;32m    605\u001b[0m dialect_args\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mcompiler_linting\u001b[39m\u001b[39m\"\u001b[39m, compiler\u001b[39m.\u001b[39mNO_LINTING)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\mysql\\pymysql.py:75\u001b[0m, in \u001b[0;36mMySQLDialect_pymysql.import_dbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_dbapi\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m__import__\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mpymysql\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymysql'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('mysql+pymysql://root:1234@127.0.0.1:3306/stock_db')\n",
    "price = pd.read_sql('select * from sample_etf;', con=engine)\n",
    "price = price.set_index(['Date'])\n",
    "engine.dispose()\n",
    "\n",
    "price.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략의 정의\n",
    "\n",
    "두번째로 시뮬레이션 하고자 하는 백테스트가 어떤 것인지를 정의해야 한다. 10개 자산을 동일비중으로 투자하며, 매월 말 리밸런싱 하는 전략을 정의해보도록 하겠다. `Strategy()` 함수 내에 algos 모듈을 이용해 백테스트 하고자 하는 내용을 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bt\n",
    "\n",
    "# 전체 자산 동일비중, 매월 말 리밸런싱\n",
    "strategy = bt.Strategy(\"Asset_EW\", [\n",
    "    bt.algos.SelectAll(),\n",
    "    bt.algos.WeighEqually(),\n",
    "    bt.algos.RunMonthly(),\n",
    "    bt.algos.Rebalance()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 먼저 전략의 이름(Asset_EW)을 입력한다.\n",
    "2. `bt.algos.SelectAll()` 함수를 통해 모든 데이터를 사용함을 정의한다.\n",
    "3. `bt.algos.WeighEqually()` 함수를 통해 동일비중으로 투자할 것을 정의한다.\n",
    "4. `bt.algos.RunMonthly()` 함수를 통해 매월말 리밸런싱 함을 정의한다.\n",
    "5. `bt.algos.Rebalance()` 함수를 통해 계산된 비중에 따라 리밸런싱 함을 정의한다.\n",
    "\n",
    "이 외에 algos 모듈을 통해 다양한 백테스트 로직을 정의할 수 있으며, 자세한 내용은 아래 사이트에서 확인할 수 있다.\n",
    "\n",
    "```\n",
    "https://pmorissette.github.io/bt/bt.html#module-bt.algos\n",
    "```\n",
    "\n",
    "### 전략의 백테스트\n",
    "\n",
    "앞에서 정의된 내용을 바탕으로 백테스트를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Documents\\office_github\\quant_py\\backtest.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m price\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# 백테스트 생성\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/office_github/quant_py/backtest.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m backtest \u001b[39m=\u001b[39m bt\u001b[39m.\u001b[39mBacktest(strategy, data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'price' is not defined"
     ]
    }
   ],
   "source": [
    "data = price.dropna()\n",
    "\n",
    "# 백테스트 생성\n",
    "backtest = bt.Backtest(strategy, data)\n",
    "\n",
    "# 백테스트 실행\n",
    "result = bt.run(backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 가격 데이터 중 ETF의 시작 시점이 모두 다르므로, `dropna()` 함수를 통해 NA를 모두 제거하여 시작시점을 동일하게 만든다.\n",
    "2. `Backtest()` 함수를 통해 백테스트를 생성할 수 있으며, 앞에서 정의한 백테스트 정의(strategy)와 가격 데이터(data)를 입력한다.\n",
    "3. `run()` 함수를 통해 백테스트를 실행하며, 앞에서 생성된 백테스트(backtest)를 입력한다.\n",
    "\n",
    "### 결과에 대한 평가\n",
    "\n",
    "위에서 시뮬레이션 된 백테스트의 결과를 살펴보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백테스트 결과에서 `prices`를 입력하면 누적수익률이 데이터프레임 형태로 나타나며, 시작시점을 100으로 환산하여 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.prices.to_returns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prices`에 추가로 `to_returns()`를 입력하면, 수익률이 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "result.plot(figsize=(10, 6), legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot()` 메서드를 통해 누적수익률을 그래프로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_security_weights().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_security_weights()` 메서드를 통해 각 종목 별 투자 비중을 확인할 수도 있다. 이를 그림으로 나타내보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "ax = result.get_security_weights().plot.area(figsize=(10, 6),\n",
    "                                             ylim=[0, 1],\n",
    "                                             legend=False,\n",
    "                                             colormap=cm.jet)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.margins(0, 0)\n",
    "plt.legend(reversed(handles),\n",
    "           reversed(labels),\n",
    "           loc='lower right',\n",
    "           bbox_to_anchor=(1.15, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `area()`를 통해 면적 그래프를 나타내며, $y$축의 범위는 0에서 1, 범례(legend)는 제외, 색 구분은 cm.jet을 이용한다.\n",
    "2. `get_legend_handles_labels()`를 통해 범례를 받아온다.\n",
    "3. 좌우 마진을 0으로 둔다.\n",
    "4. `legend()` 함수를 통해 범례를 나타내며, 그래프와 색 순서를 맞추기 위해 `reversed()`를 통해 순서를 바꾼다. 또한 위치는 오른쪽 아래(lower right)의 (1.15, 0) 지점으로 한다.\n",
    "5. 그림을 나타낸다.\n",
    "\n",
    "매월 말 리밸런싱을 하므로, 대부분의 구간에서 모든 자산에 10%씩 균등하게 투자된다. 이번에는 각종 성과지표를 확인해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`display()` 메서드를 통해 각종 성과 측정치를 구할 수 있다. 각 지표가 의미하는 바는 다음과 같다.\n",
    "\n",
    "- Start; 시작일\n",
    "- End: 종료일\n",
    "- Risk-free rate: 무위험 수익률\n",
    "- Total Return: 총 수익률\n",
    "- Sharpe: 샤프지수 (평균 수익률/변동성)\n",
    "- Sortino: 소티노지수 (평균 수익률/마이너스 수익률의 변동성)\n",
    "- CAGR: 연평균 수익률\n",
    "- Max drawdown: 최대 손실률 (MDD)\n",
    "- Calmar Ratio: 칼마지수 (수익률/MDD)\n",
    "- MTD / 3m / 6m / YTD: 금월, 3개월, 6개월, 올해 수익률\n",
    "- 1Y / 3Y (ann.) / 5Y (ann.) / 10Y (ann.): 1년 / 3년 / 5년 / 10년 기준 연율화 수익률\n",
    "- Since Incep. (ann): 시작 이후 연율화 수익률\n",
    "- Mean (ann.): 연평균 수익률\n",
    "- Vol (ann.): 연평균 변동성\n",
    "- Skew: 왜도\n",
    "- Kurt: 첨도\n",
    "- Best: 최고 수익률\n",
    "- Worst: 최저 수익률\n",
    "- Avg. Drawdown: 손실(Drawdown)의 평균\n",
    "- Avg. Drawdown Days: 손실(Drawdown) 발생 후 회복까지 평균일수\n",
    "- Avg. Up Month: 상승한 달의 평균 수익률\n",
    "- Avg. Down Month: 하락한 달의 평균 수익률\n",
    "- Win Year %: 연도별 양의 수익률을 기록할 확률\n",
    "- Win 12m %: 12개월 투자했을 시 양의 수익률을 기록할 확률\n",
    "\n",
    "## 정적 자산배분: 올웨더 포트폴리오\n",
    "\n",
    "자산배분은 포트폴리오 내에 다양한 자산에 분산 투자하여 위험을 줄이고 일정수준의 수익률 달성하고자 하는 방법이다. 이러한 자산 배분은 크게 '정적 자산배분'과 '동적 자산배분'으로 나뉜다.\n",
    "\n",
    "정적 자산배분은 주식과 채권 등 자산에 대한 비중을 어떠한 시장 상황에서도 6:4 혹은 8:2로 배분하고 유지하는 전략이다. 대표적인 정적 자산배분 전략은 레이 달리오가 운용하는 기법으로 유명해진 올웨더 포트폴리오가 있다. 레이 달리오는 세계 최대 헤지펀드인 브릿지워터(Bridgewater Associate)의 설립자이다. 그는 시시각각 변화는 경제 상황속에서 어떻게 자산배분을 해도 견딜수 있는 포트폴리오를 구상하였으며, 이것이 올웨더 포트폴리오다. 경제환경은 크게 경제 성장률과 물가 상승률로 나눌 수 있으며, 각 국면마다 우수한 성과를 보이는 자산은 다르다.\n",
    "\n",
    "```{figure} image/backtest/allweather.png\n",
    "---\n",
    "name: allweather\n",
    "---\n",
    "경제환경의 구분\n",
    "```\n",
    "\n",
    "1. 경제 성장률이 높은 구간에서는 위험 자산의 성과가 우수하다.\n",
    "2. 경제 성장률이 낮은 구간에서는 채권의 성과가 우수하다. \n",
    "3. 물가 상승률이 높은 구간에서는 원자재나 신흥국 채권의 성과가 우수다. \n",
    "4. 물가 상승률이 낮은 구간에서는 주식과 채권의 성과가 우수하다.\n",
    "\n",
    "올웨더 포트폴리오는 네 가지 상황 중 하나를 예측하기 보다는, 각각의 상황에 맞는 자산을 모두 포트폴리오에 담아 미리 대비한다. 또한 각 상황이 올 확률이 25%씩 같다고 가정할 경우, 자산별 투자비중은 {numref}`aw`와 같다.\n",
    "\n",
    "```{figure} image/backtest/aw.png\n",
    "---\n",
    "name: aw\n",
    "---\n",
    "올웨더 포트폴리오 투자 비중\n",
    "```\n",
    "\n",
    "올웨더 포트폴리오의 투자 비중을 이용해 백테스트를 해보도록 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = price[['SPY', 'TLT', 'IEF', 'GLD', 'DBC']].dropna()\n",
    "\n",
    "aw = bt.Strategy('All Weather', [\n",
    "    bt.algos.SelectAll(),\n",
    "    bt.algos.WeighSpecified(SPY=0.3, TLT=0.4, IEF=0.15, GLD=0.075, DBC=0.075),\n",
    "    bt.algos.RunQuarterly(),\n",
    "    bt.algos.Rebalance()\n",
    "])\n",
    "aw_backtest = bt.Backtest(aw, data)\n",
    "aw_result = bt.run(aw_backtest)\n",
    "\n",
    "aw_result.plot(figsize=(10, 6), title='All Weather', legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. price 데이터 중 주식(SPY), 장기채(TLT), 중기채(IEF), 금(GLD), 원자재(DBC)에 해당하는 데이터만 선택한다.\n",
    "2. 전략을 정의해주며, `bt.algos.WeighSpecified()`에 각 자산별 비중을 직접 입력한다. 또한 `bt.algos.RunQuarterly()`를 통해 분기별 리밸런싱을 정의한다.\n",
    "3. 백테스트를 생성 및 실행한다.\n",
    "\n",
    "이번에는 비중을 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "ax = aw_result.get_security_weights().plot.area(figsize=(10, 6),\n",
    "                                                ylim=[0, 1],\n",
    "                                                legend=False,\n",
    "                                                colormap=cm.jet)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.margins(0, 0)\n",
    "plt.legend(reversed(handles),\n",
    "           reversed(labels),\n",
    "           loc='lower right',\n",
    "           bbox_to_anchor=(1.15, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분기 별로 리밸런싱이 이루어짐에 따라, 각 자산별 투자비중이 일정하게 유지된다. 마지막으로 성과 중 주요 지표를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw_result.stats.loc[[\n",
    "    'total_return', 'cagr', 'daily_vol', 'max_drawdown', 'calmar', 'daily_sharpe'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수많은 성과지표 중 중요한 지표만 선택하여 확인할 수 있다.\n",
    "\n",
    "## 동적 자산배분\n",
    "\n",
    "정적 자산배분이 자산 별 일정 비중을 유지하는 전략이라면, 동적 자산배분은 시장 상황에 따라 투자하는 대상과 비중을 계속해서 변경하는 전략이다. 여러 경제 상황에서 상대적으로 유리한 자산은 좋은 성과를 보일 것이며, 경제 국면은 장기간 지속되는 추세가 있으므로 모멘텀이 있는 자산에 투자하는 것이 현명한 방법일 수 있다. 모멘텀을 이용한 동적 자산배분 포트폴리오의 예시는 다음과 같다.\n",
    "\n",
    "1. 글로벌 10개 자산 중 과거 12개월 수익률이 높은 5개 자산을 선택한다.\n",
    "2. 위험균형 포트폴리오를 구성한다.\n",
    "3. 매월 말 리밸런싱을 실시한다.\n",
    "\n",
    "10개 자산에서 과거 수익률 기준 5개 자산만 선택하는 이유는 모멘텀 효과를 얻기 위해서다. {numref}`mom_rank`는 글로벌 10개 자산의 과거 6개월 수익률을 기준으로 순위를 매기고, 각 순위 별로 다음 월의 수익률이 상위 50%가 될 확률을 구한 값이다. 수익률이 높은 1~5위 까지의 자산은 다음 월에도 수익률이 높을 확률이 50%가 넘지만, 수익률이 낮은 6~10위 까지의 자산은 다음 월에 수익률이 높을 확률이 50%가 되지 않는다. 따라서 자산군 간에도 모멘텀 효과가 존재하며, 이를 활용하기 위해 모멘텀 상위 자산만을 선택해 투자한다.\n",
    "\n",
    "```{figure} image/backtest/mom_rank.png\n",
    "---\n",
    "name: mom_rank\n",
    "---\n",
    "자산군 내 모멘텀 효과\n",
    "```\n",
    "\n",
    "또한 위험균형 포트폴리오를 이용해 변동성이 지나치게 큰 자산에 의해 포트폴리오의 수익률이 크게 영향받는 일을 줄이고, 최대한 안정적인 포트폴리오를 구성한다. 동적 자산배분의 로직이 다소 복잡해 보이지만, bt 패키지에 내장된 함수를 이용할 경우 역시나 매우 손쉽게 백테스트 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = price.dropna()\n",
    "\n",
    "gdaa = bt.Strategy('GDAA', [\n",
    "    bt.algos.SelectAll(),\n",
    "    bt.algos.SelectMomentum(n=5, lookback=pd.DateOffset(years=1)),\n",
    "    bt.algos.WeighERC(lookback=pd.DateOffset(years=1)),\n",
    "    bt.algos.RunMonthly(),    \n",
    "    bt.algos.Rebalance()\n",
    "])\n",
    "\n",
    "gdaa_backtest = bt.Backtest(gdaa, data)\n",
    "gdaa_result = bt.run(gdaa_backtest)\n",
    "\n",
    "gdaa_result.plot(figsize=(10, 6),\n",
    "                 title='Global Dynamic Asset Allocation',\n",
    "                 legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `bt.Strategy()` 내에 전략을 정의해준다.\n",
    "    - `bt.algos.SelectAll()`: 전체 데이터를 선택한다.\n",
    "    - `bt.algos.SelectMomentum(n=5, lookback=pd.DateOffset(years=1))`: 모멘텀 상위 종목을 선택하며 갯수는 5개, 모멘텀 관측 기간은 과거 1년으로 한다.\n",
    "    - `bt.algos.WeighERC(lookback = pd.DateOffset(years=1))`: ERC 즉 위험균형 포트폴리오를 구성하며, 분산-공분산 계산을 위한 수익률은 과거 1년 데이터를 이용한다.\n",
    "    - `bt.algos.RunMonthly()`: 매월 리밸런싱을 실시한다.    \n",
    "    - `bt.algos.Rebalance()`: 리밸런싱을 정의한다.\n",
    "2. 백테스트를 생성 및 실행한다.\n",
    "\n",
    "이처럼 algos 모듈 내의 각종 함수를 이용하면 다양한 전략을 손쉽게 정의 및 백테스트 할 수 있다.\n",
    "\n",
    "```{note}\n",
    "그래프를 살펴보면 처음 1년간은 수익률에 변화가 없으며, 이는 모멘텀 관측을 위한 1년 간은 투자를 할 수 없기 때문이다. 성과를 평가할 때는 이처럼 투자가 이루어지지 않는 기간을 제외하고 실제 투자가 이루어진 부분부터 평가해야 한다.\n",
    "```\n",
    "\n",
    "### 거래 비용 고려하기\n",
    "\n",
    "정적 자산배분과는 달리 동적 자산배분은 매 시점마다 투자하는 대상 및 투자비중이 변한다. 비중을 확인해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "wt = gdaa_result.get_security_weights().reindex(columns=price.columns)\n",
    "ax = wt.plot.area(figsize=(10, 6), ylim=[0, 1], legend=False, colormap=cm.jet)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.margins(0, 0)\n",
    "plt.legend(reversed(handles),\n",
    "           reversed(labels),\n",
    "           loc='lower right',\n",
    "           bbox_to_anchor=(1.15, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 정적 자산배분보다 투자 비중의 변화가 상당히 심한것을 확인할 수 있다. 이는 수익률 상위 5개에 해당하는 자산이 매월 말 바뀌며, 위험균형 포트폴리오를 구성하는 비중이 계속해서 바뀌기 때문이다. 모델 포트폴리오의 경우 이러한 점을 신경쓰지 않지만, 실제 투자에서는 잦은 턴오버로 인한 매매비용, 세금, 기타비용 등이 매우 중요해진다. 해당 전략의 턴오버를 살펴보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdaa_backtest.turnover.plot(figsize=(10, 6), legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 백테스트에서 `turnover` 메서드를 통해 턴오버를 구할 수 있다. 매월 상당한 턴오버가 발생하므로, 이를 고려한 수익률을 추가로 살펴볼 필요가 있다. 매수 혹은 매도당 발생하는 세금, 수수료, 시장충격 등 총 비용을 0.2%로 가정하여 백테스트를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdaa_backtest_net = bt.Backtest(gdaa,\n",
    "                                data,\n",
    "                                name='GDAA_net',\n",
    "                                commissions=lambda q, p: abs(q) * p * 0.002)\n",
    "gdaa_result = bt.run(gdaa_backtest, gdaa_backtest_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `bt.Backtest()` 함수 내에 기존에 정의된 백테스트인 gdaa를 그대로 사용하며, commissions 부분에 수수료를 계산하는 부분을 입력한다. q는 quantity(주수), p는 price(주가)를 의미하며, 즉 총 거래 가격에서 0.2%가 수수료로 나간다고 가정한다.\n",
    "2. `bt.run()` 내에 기존에 생성된 백테스트 내용(gdaa_backtest)과 새롭게 생성된 백테스트 내용(gdaa_backtest_net)을 동시에 입력하면, 두 개의 백테스트가 한번에 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdaa_result.prices.plot(figsize=(10, 6),\n",
    "                        title='Global Dynamic Asset Allocation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 비용을 고려하지 않은 포트폴리오(GDAA)에 비해, 비용을 차감한 포트폴리오(GDAA_net)의 수익률이 시간이 지남에 따라 서서히 감소한다. 모델 포트폴리오와 실제 포트폴리오 수익률 간의 차이는 매매시 비용이 크거나 턴오버가 높을수록 더욱 벌어지므로, 실제 매매에서는 비용과 턴오버를 줄이는 것이 매우 중요하다.\n",
    "\n",
    "## 추세추종 전략 백테스트\n",
    "\n",
    "추세추종이란 주가가 동일한 방향으로 지속될 것이라는데 베팅하는 것이다. 추세추종, 혹은 모멘텀 전략은 월스트리트에서 가장 오래된 투자전략 중 하나로써, 무려 1838년에 출간된 책에도 설명될 만큼 역사가 길고, 현재에도 가장 많이 사용되는 전략 중 하나이다.\n",
    "\n",
    "### 마켓 타이밍 전략\n",
    "\n",
    "대표적인 추세추종 전략인 이동평균선을 이용한 트레이딩의 백테스트를 진행해보도록 하겠다. 메브 파버(Meb Faber)는 본인의 논문을 통해, 시점 선택(Market Timing) 전략을 사용할 경우 단순히 매수 후 보유하는 것 대비 극심한 하락장에서 낙폭을 줄일 수 있으며, 이로 인해 위험 대비 수익률을 올릴 수 있다고 설명하였다. 논문에서 말하는 시점 선택의 투자 규칙은 다음과 같다.\n",
    "\n",
    "$$ 주가 > 10개월 이동평균 → 매수$$\n",
    "$$ 주가 < 10개월 이동평균 → 매도\\ 및\\ 현금보유$$\n",
    "\n",
    "즉 주가가 10개월 이동평균 보다 위에 있다는 것은 상승추세를 의미하므로 매수 포지션을, 10개월 이동평균 보다 아래에 있다는 것을 하락추세를 의미하므로 현금 보유를 통해 하락 방어를 하고자 한다. 먼저 해당 규칙을 미국 S&P 500를 추종하는 SPY ETF에 적용하는 예제를 살펴보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMA\n",
    "import talib\n",
    "\n",
    "data = price[['SPY']].dropna()\n",
    "sma = data.apply(lambda x: talib.SMA(x, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 `apply()` 함수 내부에 `SMA()`을 이용해 200일(10개월) 이동평균을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bt\n",
    "\n",
    "bt_sma = bt.Strategy('Timing', [\n",
    "    bt.algos.SelectWhere(data > sma),\n",
    "    bt.algos.WeighEqually(),\n",
    "    bt.algos.Rebalance()\n",
    "])\n",
    "\n",
    "bt_sma_backtest = bt.Backtest(bt_sma, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bt.algos.SelectWhere()`는 입력값이 True 일때만 투자를 하도록 정의한다. 즉, ETF 가격에 해당하는 data가 이동평균에 해당하는 sma 보다 클 때에만 투자를 한다. 나머지는 위에서 살펴본 것들과 동일한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_and_hold(data, name):\n",
    "\n",
    "    # 벤치마크 전략 생성\n",
    "    bt_strategy = bt.Strategy(name, [        \n",
    "        bt.algos.SelectAll(),\n",
    "        bt.algos.WeighEqually(),\n",
    "        bt.algos.RunOnce(),\n",
    "        bt.algos.Rebalance()\n",
    "    ])\n",
    "    # Return the backtest\n",
    "    return bt.Backtest(bt_strategy, data)\n",
    "\n",
    "\n",
    "# 벤치마크 전략 백테스트\n",
    "stock = buy_and_hold(data[['SPY']], name='stock')\n",
    "\n",
    "# 두개 백테스트 동시에 실행\n",
    "bt_sma_result = bt.run(bt_sma_backtest, stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `buy_and_hold()` 함수를 통해 단순 매수 후 보유의 경우를 정의한다. `bt.algos.RunOnce()`는 리밸런싱이 없이 처음 상태가 그대로 유지되는 것이다.\n",
    "2. SPY의 매수 후 보유 전략을 생성한다.\n",
    "3. 앞에서 생성된 추세추종 전략과, 매수 후 보유의 백테스트를 동시에 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bt_sma_result.prices.iloc[201:, ].rebase().plot(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추세추종 전략의 경우 이동평균 계산을 위해 처음 200 일간은 투자가 되지 않으므로 매수 후 보유 전략과 시작 시점이 일치하지 않는다. 따라서 200일이 지난 후부터의 데이터를 선택한다. 그 후 `rebase()` 함수를 이용해 데이터의 시작시점을 다시 100으로 만든다.\n",
    "\n",
    "추세추종 전략을 사용할 경우 2000년 IT 버블이나 2008년 금융위기시 하락폭이 제한된다. 즉 하락추세가 시작되면 주식을 모두 매도하여, 추가적인 하락을 방어한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_sma_result.prices.iloc[201:, ].rebase().to_drawdown_series().plot(\n",
    "    figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_drawdown_series()` 함수는 낙폭(drawdown)을 계산한다. 앞서 언급한 것 처럼 추세추종 전략을 사용할 경우 하락 방어가 우수하다. 반면 코로나19 사태 직후인 2020년 3월의 경우 추세추종 전략은 추세가 깨져 투자를 하지 않지만, 주식 시장이 급반등 함에 따라 매수 후 보유 전략의 상승분을 따라가지 못하기도 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_sma_result.stats.loc[[\n",
    "    'total_return', 'cagr', 'daily_vol', 'max_drawdown', 'calmar', 'daily_sharpe', 'daily_sortino'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수익률 자체는 단순 보유전략(stock)이 높지만 변동성이나 MDD와 같은 위험지표는 마켓 타이밍 전략(Timing)이 훨씬 낮다. 결과적으로 위험을 고려한 성과 지표는 마켓 타이밍 전략이 더 우수하다.\n",
    "\n",
    "### 파라미터 최적화\n",
    "\n",
    "과연 200일(10개월) 이동평균을 사용하는 것이 최적일까? 혹은 다른 값을 사용했을 때 수익률이 더 좋을수 있지 않을까? 이러한 질문은 트레이더들이 항상 하는 질문이다. '200일'과 같이 우리가 임의로 정하는 변수를 파라미터(parameter)라 하며, 성과가 최대화 되는 파라미터를 찾는 것을 파라미터 최적화라고 한다. 트레이딩에서 이러한 파라미터 최적화는 매우 중요한 작업이다. 앞선 마켓 타이밍 전략에서 이동평균을 계산할 때 사용하는 일수를 변경해가며 수익률을 확인해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import bt\n",
    "\n",
    "data = price[['SPY']].dropna()\n",
    "\n",
    "def timing(price, n):\n",
    "\n",
    "    sma = price.apply(lambda x: talib.SMA(x, n))\n",
    "    stragety = bt.Strategy(n, [\n",
    "        bt.algos.SelectWhere(price > sma),        \n",
    "        bt.algos.WeighEqually(),\n",
    "        bt.algos.Rebalance()\n",
    "    ])\n",
    "\n",
    "    backtest = bt.Backtest(stragety, price)\n",
    "\n",
    "    return (backtest)\n",
    "\n",
    "n_20 = timing(data, 20)\n",
    "n_60 = timing(data, 60)\n",
    "n_100 = timing(data, 100)\n",
    "n_150 = timing(data, 150)\n",
    "n_200 = timing(data, 200)\n",
    "n_250 = timing(data, 250)\n",
    "\n",
    "result = bt.run(n_20, n_60, n_100, n_150, n_200, n_250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이동평균을 계산한 후, 백테스트를 생성하는 부분을 `timing()` 함수로 작성한다.\n",
    "2. 20일부터 250일까지 이동평균을 이용한 마켓타이밍 모델의 백테스트를 생성한다.\n",
    "3. 모든 백테스트를 한번에 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "result.prices[250:].rebase().plot(figsize=(10, 6), colormap=cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "누적수익률을 확인해보면 단기 보다는 장기 이동평균을 사용할 수록 우수한 성과를 기록한다. 그러나 예를 들어 250일 이동평균이 최고의 수익률을 기록한다고 이것이 최적의 파라미터라고 말하기는 힘들다. 장기 이동평균을 사용하는 것이 단기 이동평균을 사용하는 것보다 성과가 좋은 이유는, 장기 이동평균이 장기적인 추세를 더 잘 반영하기 때문일 수 있다. 그러나 같은 장기 이동평균에서도 250일이 200일 보다 우수한 것은 단순히 우연의 결과일 수 있으며, 백테스트 기간을 다르게 하면 전혀 다른 결과가 나타날 수도 있다.\n",
    "\n",
    "백테스트 기간에서 최적화된 파라미터가 향후에도 최고의 수익률을 기록할 것이라는 생각은 위험하다. 백테스트에서는 엄청나게 우수한 성과를 보였던 전략을 찾아 용기있게 실제 투자에 나섰다가 과최적화의 저주에 빠져 실망스러운 수익률로 이어지는 경우도 종종 목격한다. 따라서 모델에 사용되는 파라미터의 갯수는 최대한 작게, 그리고 인샘플(in-sample) 뿐만 아니라 아웃오브샘플(out-of-sample) 테스트에서도 뛰어난 성과를 보이는 파라미터를 택하는 것이 좋다.\n",
    "\n",
    "### 롱숏 전략\n",
    "\n",
    "지금까지는 주가가 이동평균선 위에 있을 때 매수하며 그렇지 않으면 현금을 보유하는 '롱온리(Long-Only)' 전략에 대한 백테스트를 실시했다. 그러나 추세추종 전략은 상승추세에 대한 베팅뿐만 아니라 공매도, 인버스 ETF 혹은 선물매도 포지션을 통해 하락추세에도 베팅할 수 있다. \n",
    "\n",
    "흔히 단기 이동평균선이 중장기 이동평균선을 뚫고 올라가는 골든크로스의 경우 상승추세에 대한 신호를, 반대로 뚫고 내려가는 데드크로스의 경우 하락추세에 대한 신호를 나타낸다. 과연 이러한 신호를 이용해 트레이딩 했을 때 성과가 어떤지 살펴보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "data = price[['SPY']]\n",
    "SMA_200 = data.apply(lambda x: talib.SMA(x, 200))\n",
    "SMA_60 = data.apply(lambda x: talib.SMA(x, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 장기추세에 해당하는 200일 지수 이동평균과 단기추세에 해당하는 60일 지수 이동평균을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = SMA_200.copy()\n",
    "signal[SMA_60 >= SMA_200] = 1\n",
    "signal[SMA_60 < SMA_200] = -1\n",
    "signal[signal.isnull()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만일 60일 이동평균이 200일 이동평균보다 위에 있을 경우(골든크로스) 100% 투자 즉 매수를 하며, 반대의 경우(데드크로스) -100% 투자 즉 매도를 한다. 이동평균을 계산하기 위한 처음 200일 부분은 데이터가 없으므로 포지션을 0으로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bind = pd.concat([data, SMA_200, SMA_60, signal], axis=1)\n",
    "bind.columns = ['SPY', 'SMA 200', 'SMA 60', 'signal']\n",
    "bind.loc['2018':].plot(figsize=(10, 6), secondary_y=['signal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018년 이후부터 주가와 각 이동평균선, 신호를 그림으로 나타내보면 단기 이동평균선(SMA 60)이 장기 이동평균선(SMA 200) 위에 있을 경우에는 매수(1), 그렇지 않을 때는 매도(-1)를 하는 것이 확인된다. 이제 해당 전략의 백테스트를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bt\n",
    "\n",
    "strategy = bt.Strategy(\n",
    "    'SMA_crossover',\n",
    "    [bt.algos.SelectAll(),\n",
    "     bt.algos.WeighTarget(signal),\n",
    "     bt.algos.Rebalance()])\n",
    "backtest = bt.Backtest(strategy, data)\n",
    "result = bt.run(backtest)\n",
    "\n",
    "result.plot(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bt.algos.WeighTarget()` 함수 내에 각 시점별 비중을 입력하면, 해당 시점과 비중에 맞춰 리밸런싱이 실시된다. 이를 통해 해당 패키지에서 함수 형태로 제공하지 않는 매우 복잡한 전략의 백테스트도 시기별 비중을 직접 계산해 얼마든지 실행할 수 있다.\n",
    "\n",
    "결과를 살펴보면 장기간 동안 우상향을 하지만 2011년, 2015~16년, 2020년 등에는 엄청난 낙폭을 기록하기도 했다. 월별 및 연도별 수익률을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.display_monthly_returns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `display_monthly_returns()` 메서드를 통해 월단위 및 연단위 수익률을 확인할 수 있다. 2020년에는 코로나 이후 주가가 급등했음에도 불구하고, 롱숏 전략은 -20.55%의 큰 손실을 기록하였다. 왜 이런 결과가 나왔는지 해당 구간을 자세히 살펴보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([bind, result.prices],\n",
    "          axis=1).loc['2020'].rebase().plot(figsize=(10, 6),\n",
    "                                            secondary_y=['signal'],\n",
    "                                            alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코로나 사태로 인해 2020년 3월부터 미국 주식(SPY)은 급격하게 하락하기 시작했으며, 3월 중순에는 60일 이동평균선이 200일 이동평균선을 하회함에 따라 숏 신호가 발생하였다. 그러나 공교롭게도 해당 시점부터 시장은 바닥을 다지고 엄청난 상승을 보였으며, 전략(SMA_crossover)에서는 숏 포지션을 취하고 있는 만큼 손실이 발생하기 시작한다. 6월이 되서야 다시 골든크로스가 발생하여 롱 포지션으로 전환하였지만, 불과 3달동안 복구할 수 없을 정도의 손실을 입게 되었다. 실제로 추세추종 전략을 사용하는 많은 펀드들이 2020년 3월부터 6월까지 막대한 손실을 입었다. 2020년 1~3월에는 롱 포지션에서 손실을 입고, 3월부터는 숏 포지션에서 손실을 입어 양방향에서 모두 손실을 입은 것이다.\n",
    "\n",
    "만일 롱온리 전략을 택했다면 3월부터 6월까지 단순히 수익을 얻지 못한것에 그쳤겠지만, 숏 포지션으로 인해 손실이 배가 된 것이다. 이처럼 숏 베팅은 하락 시장에서도 돈을 벌 수 있게 해주지만, 예상치 못한 급반등이 나올 경우 손실을 입히는 양날의 검이 되기도 한다. 이를 방지하기 위해 트레이딩에서는 다양한 신호의 결합, 손실제한(스탑로스, 로스컷) 등을 추가하기도 한다.\n",
    "\n",
    "## 평균회귀 전략 백테스트\n",
    "\n",
    "추세추종 전략은 주가가 동일한 방향으로 지속된다고 보는 반면, 평균회귀 전략은 주가가 평균으로 회귀한다고 보며 이에 베팅한다. 주가가 무한정 한방향으로 지속될 수는 없기에 추세추종 전략과 평균회귀 전략을 잘 조합할 필요가 있다.\n",
    "\n",
    "### RSI를 이용한 전략\n",
    "\n",
    "RSI는 일정기간 동안 주가의 상승폭과 하락폭의 크기를 비교해 상승과 하락의 상대적인 강도를 나타낸 지표로써, 일반적으로 RSI가 70 이상일 경우 과매수 구간으로써 매도할 때를, 30 이하일 경우 과매도 구간으로써 매수해야 할 때로 여겨진다. 이에 대한 백테스트를 실행해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "data = price[['SPY']]\n",
    "spy_rsi = data.apply(lambda x: talib.RSI(x, 14))\n",
    "\n",
    "signal = spy_rsi.copy()\n",
    "signal[spy_rsi > 70] = -1\n",
    "signal[spy_rsi < 30] = 1\n",
    "signal[(spy_rsi <= 70) & (spy_rsi >= 30)] = 0\n",
    "signal[signal.isnull()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 `apply()` 함수 내부에 `RSI()`을 이용해 14일 기준 RSI를 구한다. 그 후 RSI가 70을 초과하면 -1(숏 포지션), 30 미만이면 1(롱 포지션), 30과 70 사이면 0(뉴트럴)인 신호를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.subplots(figsize=(10, 6), sharex=True)\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[2, 1])\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1 = data['SPY'].plot()\n",
    "ax1.set_xlabel('')\n",
    "ax1.axes.xaxis.set_ticks([])\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2 = spy_rsi['SPY'].plot(color='black', ylim=[0, 100])\n",
    "ax2 = plt.axhline(y=30, color='red', linestyle='-')\n",
    "ax2 = plt.axhline(y=70, color='red', linestyle='-')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위쪽의 그래프는 주가를 나타내며, 아래쪽의 그래프는 RSI를 나타낸다. 이제 만들어진 신호를 바탕으로 백테스트를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = bt.Strategy('RSI_MeanReversion',\n",
    "                       [bt.algos.WeighTarget(signal),\n",
    "                        bt.algos.Rebalance()])\n",
    "backtest = bt.Backtest(strategy, data)\n",
    "result = bt.run(backtest)\n",
    "\n",
    "result.plot(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSI를 이용하여 트레이딩을 할 경우 장기간으로 큰 손실없이 잘 작동하지만, 과매수 혹은 과매도로 인한 투자 신호가 나타나는 경우가 드물어 누적수익률 자체도 그렇게 높지 않다. 반면 2020년의 경우 추세추종 전략과는 반대로 3월 급락장에서 과매도 신호로 인해 매수를 함으로써, 반등으로 인해 상당한 수익을 거두기도 한다. 이처럼 추세추종과 평균회귀는 서로 상반되는 특징이 있으므로, 이를 잘 조합하면 훨씬 안정적인 수익을 거둘 수 있는 트레이딩 전략을 개발할 수도 있다.\n",
    "\n",
    "성과 중 주요 지표를 확인해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stats.loc[['total_return', 'cagr', 'daily_vol', 'max_drawdown', 'calmar', 'daily_sharpe']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 볼린저 밴드를 이용한 전략\n",
    "\n",
    "이번에는 볼린저 밴드를 이용한 평균회귀 전략을 백테스트 해보도록 하겠다. 볼린저밴드는 이동평균선을 중심으로 일정 표준편차를 상한선과 하한선으로 설정한 밴드다. 주가가 정규분포를 따른다면 주가의 움직임은 상한선과 하한선으로 구성된 밴드 내에서만 움직일 확률이 높다. 따라서 주가가 상한선 위에 있다는 것은 과매수 상태이므로 하락할 가능성이 높으르로 숏 포지션을, 하단선 아래에 있다는 것은 과매도 상태이므로 상승할 가능성이 높으므로 롱 포지션을 취한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_2sd, mid_2sd, lower_2sd = talib.BBANDS(data['SPY'],\n",
    "                                             nbdevup=2,\n",
    "                                             nbdevdn=2,\n",
    "                                             timeperiod=20)\n",
    "\n",
    "bb = pd.concat([upper_2sd, mid_2sd, lower_2sd, data['SPY']], axis=1)\n",
    "bb.columns = ['Upper Band', 'Mid Band', 'Lower Band', 'SPY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BBANDS()` 함수를 이용해 20일 기준 2 표준편차에 해당하는 볼린저 밴드의 상, 중, 하단 값을 계산한 후 하나의 데이터프레임으로 묶어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "signal = data.copy()\n",
    "signal['SPY'] = np.nan\n",
    "\n",
    "signal[bb['SPY'] > bb['Upper Band']] = -1\n",
    "signal[bb['SPY'] < bb['Lower Band']] = 1\n",
    "signal[signal.isnull()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주가가 상한선 위에 있을 경우 -1(숏 포지션), 주가가 하한선 아래에 있을 경우 1(롱 포지션), 그 외의 경우 0(뉴트럴)의 신호를 만둔다. 해당 신호를 바탕으로 백테스트를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = bt.Strategy('BB',\n",
    "                       [bt.algos.WeighTarget(signal),\n",
    "                        bt.algos.Rebalance()])\n",
    "backtest = bt.Backtest(strategy, data)\n",
    "result = bt.run(backtest)\n",
    "\n",
    "result.plot(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSI와 마찬가지로 볼린저밴드를 이용한 평균회귀 트레이딩을 할 경우에도 장기간으로 큰 손실없이 잘 작동한다. 주요 성과 지표는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stats.loc[['total_return', 'cagr', 'daily_vol', 'max_drawdown', 'calmar', 'daily_sharpe']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bt 패키지의 함수 \n",
    "\n",
    "마지막으로 bt 패키지의 함수들을 정리해보도록 하겠다.\n",
    "\n",
    "- 유니버스 선택\n",
    "    - `bt.algos.SelectAll()`: 모든 종목 선택\n",
    "    - `bt.algos.SelectHasData()`: 일정 갯수 이상의 데이터가 있는 종목 선택\n",
    "    - `bt.algos.SelectMomentum()`: 모멘텀 상위 종목 선택, `bt.algos.SelectAll()`을 먼저 불러와야 함\n",
    "    - `bt.algos.SelectWhere()`: 입력값이 True 일때만 투자\n",
    "\n",
    "- 비중 선택\n",
    "    - `bt.algos.WeighEqually()`: 동일 비중\n",
    "    - `bt.algos.WeighSpecified()`: 비중 직접 입력. 리밸런싱 마다 동일한 값 적용.\n",
    "    - `bt.algos.WeighTarget(signal)`: 비중 직접 입력. 리밸런싱 마다 입력한 값 적용.\n",
    "    - `bt.algos.WeighERC()`: 위험균형 전략\n",
    "    - `bt.algos.WeighInvVol()`: 역변동성 전략\n",
    "    - `bt.algos.WeighMeanVar()`: 최대샤프지수 전략\n",
    "\n",
    "- 리밸런싱 시점\n",
    "    - `bt.algos.RunOnce()`: 처음 한번만 리밸런싱\n",
    "    - `bt.algos.RunDaily()`: 매일 리밸런싱\n",
    "    - `bt.algos.RunMonthly()`: 매월 리밸런싱\n",
    "    - `bt.algos.RunQuarterly()`: 매분기 리밸런싱\n",
    "    - `bt.algos.RunWeekly()`: 매주 리밸런싱\n",
    "    - `bt.algos.RunYearly()`: 매년 리밸런싱\n",
    "\n",
    "- 리밸런싱 방법\n",
    "    - `bt.algos.Rebalance()`: 선택한 시점과 비중에 따라 리밸런싱\n",
    "    - `bt.algos.RebalanceOverTime()`: n일에 걸쳐 리밸런싱\n",
    "\n",
    "- 기타 함수들\n",
    "    - `plot_weights()`: 투자 비중 출력\n",
    "    - `get_security_weights()`: 투자 비중을 데이터프레임 형태로 반환\n",
    "    - `prices()`: 누적수익률을 데이터프레임 형태로 구하기\n",
    "    - `prices.rebase()`: 특정 시점부터 다시 100으로 환산\n",
    "    - `prices.to_returns()`: 수익률 계산\n",
    "    - `display()`: 성과 측정치\n",
    "    - `display_monthly_returns()`: 월간 수익률 구하기\n",
    "    - `turnover()`: 회전율 구하기\n",
    "\n",
    "```{note}\n",
    "위에서 백테스트한 추세추종과 평균회귀 전략의 경우 신호가 발생하면 해당일 종가에 포지션을 취한다고 가정했다. 그러나 현실에서는 종가 직전까지 발생한 신호를 바탕으로 종가에 매매를 하거나 종가로 계산된 신호를 바탕으로 다음날 시가에 매매를 해야하므로, 백테스트의 수익률과 실제 수익률은 상당히 차이가 있을 수 있다. 또한 매매수수료와 시장충격으로 인해 백테스트의 수익률과 실제 수익률간 차이가 발생할 수도 있다.\n",
    "```\n",
    "\n",
    "```{note}\n",
    "크롤링으로 수집한 데이터로 개별 주식에 대한 백테스트를 하기에는 생존 편향, 소급 편향 등의 문제가 있으며, 난이도 역시 매우 높다. 두물머리에서 제공하는 '올라떼' 사이트에서는 전 세계 주식을 대상으로 양질의 데이터를 통한 각종 팩터 모형에 대한 백테스트를 클릭만으로 수행할 수 있으니 이를 참조하기 바란다.\n",
    "\n",
    "https://allatte.com/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
